{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\mdfm9\\\\Desktop\\\\Handpose\\\\handpose\\\\src\\\\App.js\";\nimport React, { useRef } from 'react';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from \"@tensorflow-models/handpose\";\nimport Webcam from \"react-webcam\"; //import logo from './logo.svg';\n\nimport './App.css';\nimport { drawHand, drwaHand } from \"./utilities\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const runHandpose = async () => {\n    const net = await handpose.load();\n    console.log('Handpose model loaded.'); // Loop para detectar as mãos\n\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  };\n\n  const detect = async net => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.videoWidth;\n      const videoHeight = webcamRef.current.videoHeight;\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n      const hand = await net.estimateHands(video);\n      console.log(hand);\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drwaHand(hand, ctx);\n    }\n  };\n\n  runHandpose();\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"App\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 52,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"header\", {\n    className: \"App-header\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 53,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(Webcam, {\n    ref: webcamRef,\n    style: {\n      position: \"absolute\",\n      marginLeft: \"auto\",\n      marginRight: \"auto\",\n      left: 0,\n      right: 0,\n      textAlign: \"center\",\n      zindex: 9,\n      width: 640,\n      height: 480\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 11\n    }\n  }), /*#__PURE__*/React.createElement(\"canvas\", {\n    ref: canvasRef,\n    style: {\n      position: \"absolute\",\n      marginLeft: \"auto\",\n      marginRight: \"auto\",\n      left: 0,\n      right: 0,\n      textAlign: \"center\",\n      zindex: 9,\n      width: 640,\n      height: 480\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 11\n    }\n  })));\n}\n\nexport default App;","map":{"version":3,"sources":["C:/Users/mdfm9/Desktop/Handpose/handpose/src/App.js"],"names":["React","useRef","tf","handpose","Webcam","drawHand","drwaHand","App","webcamRef","canvasRef","runHandpose","net","load","console","log","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","hand","estimateHands","ctx","getContext","position","marginLeft","marginRight","left","right","textAlign","zindex"],"mappings":";AAAA,OAAOA,KAAP,IAAeC,MAAf,QAA4B,OAA5B;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,QAAZ,MAA0B,6BAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB,C,CACA;;AACA,OAAO,WAAP;AACA,SAAQC,QAAR,EAAkBC,QAAlB,QAAiC,aAAjC;;AAEA,SAASC,GAAT,GAAe;AACT,QAAMC,SAAS,GAAGP,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMQ,SAAS,GAAGR,MAAM,CAAC,IAAD,CAAxB;;AAEA,QAAMS,WAAW,GAAG,YAAW;AAC7B,UAAMC,GAAG,GAAG,MAAMR,QAAQ,CAACS,IAAT,EAAlB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,wBAAZ,EAF6B,CAG7B;;AACAC,IAAAA,WAAW,CAAC,MAAI;AACdC,MAAAA,MAAM,CAACL,GAAD,CAAN;AACD,KAFU,EAER,GAFQ,CAAX;AAKD,GATD;;AAWA,QAAMK,MAAM,GAAG,MAAOL,GAAP,IAAc;AAE3B,QAAG,OAAOH,SAAS,CAACS,OAAjB,KAA6B,WAA7B,IACAT,SAAS,CAACS,OAAV,KAAsB,IADtB,IAEAT,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAF1C,EAE4C;AACtC,YAAMD,KAAK,GAAGV,SAAS,CAACS,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGZ,SAAS,CAACS,OAAV,CAAkBG,UAArC;AACA,YAAMC,WAAW,GAAGb,SAAS,CAACS,OAAV,CAAkBI,WAAtC;AAEFb,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAZ,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC;AAEAZ,MAAAA,SAAS,CAACQ,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAX,MAAAA,SAAS,CAACQ,OAAV,CAAkBM,MAAlB,GAA0BF,WAA1B;AAEA,YAAMG,IAAI,GAAG,MAAMb,GAAG,CAACc,aAAJ,CAAkBP,KAAlB,CAAnB;AACAL,MAAAA,OAAO,CAACC,GAAR,CAAYU,IAAZ;AAEA,YAAME,GAAG,GAAGjB,SAAS,CAACQ,OAAV,CAAkBU,UAAlB,CAA6B,IAA7B,CAAZ;AACArB,MAAAA,QAAQ,CAACkB,IAAD,EAAOE,GAAP,CAAR;AAEA;AACL,GAtBD;;AAwBAhB,EAAAA,WAAW;AAGf,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAQ,IAAA,SAAS,EAAC,YAAlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI,oBAAC,MAAD;AAAQ,IAAA,GAAG,EAAIF,SAAf;AACA,IAAA,KAAK,EAAI;AACPoB,MAAAA,QAAQ,EAAE,UADH;AAEPC,MAAAA,UAAU,EAAE,MAFL;AAGPC,MAAAA,WAAW,EAAE,MAHN;AAIPC,MAAAA,IAAI,EAAE,CAJC;AAKPC,MAAAA,KAAK,EAAC,CALC;AAMPC,MAAAA,SAAS,EAAE,QANJ;AAOPC,MAAAA,MAAM,EAAC,CAPA;AAQPZ,MAAAA,KAAK,EAAC,GARC;AASPC,MAAAA,MAAM,EAAC;AATA,KADT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADJ,eAeI;AAAQ,IAAA,GAAG,EAAEd,SAAb;AACA,IAAA,KAAK,EAAI;AACPmB,MAAAA,QAAQ,EAAE,UADH;AAEPC,MAAAA,UAAU,EAAE,MAFL;AAGPC,MAAAA,WAAW,EAAE,MAHN;AAIPC,MAAAA,IAAI,EAAE,CAJC;AAKPC,MAAAA,KAAK,EAAC,CALC;AAMPC,MAAAA,SAAS,EAAE,QANJ;AAOPC,MAAAA,MAAM,EAAC,CAPA;AAQPZ,MAAAA,KAAK,EAAC,GARC;AASPC,MAAAA,MAAM,EAAC;AATA,KADT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAfJ,CADF,CADF;AAoCD;;AAED,eAAehB,GAAf","sourcesContent":["import React, {useRef} from 'react';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from \"@tensorflow-models/handpose\";\nimport Webcam from \"react-webcam\";\n//import logo from './logo.svg';\nimport './App.css';\nimport {drawHand, drwaHand} from \"./utilities\";\n\nfunction App() {\n      const webcamRef = useRef(null);\n      const canvasRef = useRef(null);\n\n      const runHandpose = async () =>{\n        const net = await handpose.load()\n        console.log('Handpose model loaded.')\n        // Loop para detectar as mãos\n        setInterval(()=>{\n          detect(net)\n        }, 100)\n\n\n      };\n\n      const detect = async (net) =>{\n\n        if(typeof webcamRef.current !== \"undefined\" &&\n           webcamRef.current !== null &&\n           webcamRef.current.video.readyState === 4){\n              const video = webcamRef.current.video;\n              const videoWidth = webcamRef.current.videoWidth;\n              const videoHeight = webcamRef.current.videoHeight;\n\n            webcamRef.current.video.width = videoWidth;\n            webcamRef.current.video.height = videoHeight;\n\n            canvasRef.current.width = videoWidth;\n            canvasRef.current.height =videoHeight;\n\n            const hand = await net.estimateHands(video);\n            console.log(hand);\n\n            const ctx = canvasRef.current.getContext(\"2d\");\n            drwaHand(hand, ctx);\n\n           }\n      };\n\n      runHandpose();\n\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n          <Webcam ref = {webcamRef}\n          style = {{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right:0,\n            textAlign: \"center\",\n            zindex:9,\n            width:640,\n            height:480\n          }\n\n          }/>\n          <canvas ref={canvasRef}\n          style = {{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right:0,\n            textAlign: \"center\",\n            zindex:9,\n            width:640,\n            height:480\n          }\n\n          }/>\n\n\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}